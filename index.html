<!DOCTYPE html>
<html>

<head>
    <title>Video-MMLU: A Massive Multi-Discipline Lecture Understanding Benchmark</title>
    <!-- consider to add our icon here -->
    <!-- <link rel="icon" href="" type="image/icon type"> -->

    <meta name="viewport" content="width=device-width, initial-scale=1">

    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels@2.0.0"></script>
    <script
        src="https://cdn.jsdelivr.net/npm/chartjs-plugin-annotation@3.0.1/dist/chartjs-plugin-annotation.min.js"></script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="website/css/bulma.min.css">
    <link rel="stylesheet" href="website/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="website/css/bulma-slider.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="website/css/fontawesome.all.min.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="./website/javascript/bulma-carousel.min.js"></script>
    <script src="./website/javascript/bulma-slider.min.js"></script>

    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p"
        crossorigin="anonymous"></script>

    <link href="https://unpkg.com/tabulator-tables@5.5.2/dist/css/tabulator_bootstrap4.min.css" rel="stylesheet">
    <script type="text/javascript" src="https://unpkg.com/tabulator-tables@5.5.2/dist/js/tabulator.min.js"></script>
    <script defer src="website/javascript/fontawesome.all.min.js"></script>
    <!-- <script src="website/javascript/peity-vanilla.js"></script> -->


    <!-- below we load some js scripts -->
    <script src="website/javascript/benchmark_table.js" type="module"></script>
    <script src="website/javascript/auto-scroll.js"></script>

    <link rel="stylesheet" href="website/css/index.css">

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-C7GJ4FYMY9"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-C7GJ4FYMY9');
    </script>

    <!-- MathJax script -->
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script type="text/javascript">
        MathJax.Hub.Config({
            tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
        });
    </script>

    <noscript>
        <p><img alt="Clicky" width="1" height="1" src="//in.getclicky.com/101339888ns.gif" /></p>
    </noscript>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
        var toggles = document.querySelectorAll('.toggle-section');
        toggles.forEach(function(toggle) {
            toggle.addEventListener('click', function() {
            var content = document.getElementById(toggle.getAttribute('aria-controls'));
            var toggleIcon = toggle.children[1].children[0];
            content.classList.toggle('is-active');
            if (content.classList.contains('is-active')) {
                toggleIcon.style.transition = 'transform 0.3s ease';
                toggleIcon.style.transform = 'rotate(180deg)';
            } else {
                toggleIcon.style.transition = 'transform 0.3s ease';
                toggleIcon.style.transform = 'rotate(0deg)';
            }
            });
        });
        });
      </script>

    <style>
        .collapse-content {
          display: none;
          margin-top: 10px;
        }
        .collapse-content.is-active {
          display: block;
        }
        /* .toggle-section .icon.is-small {
          transition: transform 0.3s ease;
        } */
        /* .toggle-section .fa-angle-up {
          transform: rotate(180deg);
        } */
      </style>
</head>

<body>

    
    <!-- Title. -->
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title is-bold">
                            <!-- <img src="website/img/mint-leaf-logo.png" alt="logo" width="40" height="40" /> -->
                            Video-MMLU: A Massive Multi-Discipline Lecture Understanding Benchmark
                        </h1>
                        <p style="color: darkred; font-weight: bold;">A more comprehensive video perception and reasoning benchmark series.</p>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://espere-1119-song.github.io/"> Enxin Song</a><sup>1</sup>,</span>
                            <span class="author-block">
                              <a href="https://rese1f.github.io/">Wenhao Chai</a><sup>2</sup>,</span>
                            <span class="author-block">
                              <a href="https://weili-0234.github.io/">Weili Xu</a><sup>1, 3</sup>,
                            </span>

                          </div>
                
                          <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="http://www.stat.ucla.edu/~jxie/">Jianwen Xie</a><sup>4</sup>,
                            </span>
                            <span class="author-block">
                                Yuxuan Liu<sup>1,3</sup>,
                            </span>
                            <span class="author-block">
                            <a href="https://cvnext.github.io/">Gaoang Wang</a><sup>1</sup>,
                            </span>
                          </div>
                                
                          <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>Zhejiang University,</span>
                            <span class="author-block"><sup>2</sup>University of Washington,</span>
                            <span class="author-block"><sup>3</sup>University of Illinois Urbana-Champaign,</span>
                            <span class="author-block"><sup>4</sup>Akool Research,</span>
                          </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                 <!-- <span class="link-block">
                                    <a class="btn btn-outline-dark"
                                     role="button">
                                    &nbsp;
                                        <i class="fas fa-file-pdf"></i>
                                        <span>&nbsp;&nbsp;Paper (Coming Soon)</span>
                                    </a> &nbsp;&nbsp;
                                 </span> -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2410.03051" class="btn btn-outline-dark"
                                        role="button">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a> &nbsp;&nbsp;
                                </span>
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="https://github.com/rese1f/aurora" class="btn btn-outline-dark" role="button">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a> &nbsp;&nbsp;

                                </span>


                                <!-- Benchmark Link. -->
                                <span class="link-block">
                                    <a href="https://huggingface.co/datasets/wchai/Video-Detailed-Caption" class="btn btn-outline-dark" role="button" style="display: inline-flex; align-items: center;">
                                        <span class="icon" style="display: inline-flex; align-items: center;">
                                            <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face" style="width: 20px; height: 18px; margin-right: 5px;">
                                        </span>
                                        <span>Video-MMLU Benchmark</span>
                                    </a> &nbsp;&nbsp;
                                </span>
                                                                                   
                            </div>
                        </div>

                    </div>
                </div>
            </div>
        </div>
    </section>


    <section class="hero teaser">
        <div class="container is-max-desktop">
          <div class="hero-body">
              <video id="teaser" autoplay muted loop playsinline controls width="100%">
                  <!-- <source src="./website/videos/eai-video-v2.mov" type="video/quicktime"> -->
                  <source src="./website/videos/teaser.mp4" type="video/mp4">
                  Your browser does not support the video tag.
              </video>
          </div>
        </div>
      </section>



    <!-- Leaderboard-->
    <section class="section" id="embodied_agent_interface_detail">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <h2 class="title is-2" style="text-align: center;">Video-MMLU Leaderboard</h2>
                <br>
                <div class="content has-text-justified">
                    <div class="has-text-centered">
                        <h4 class="title is-4">ü§© Welcome to the Video-MMLU lecture hall! Is your model ready to be tested? </h4>
                        <br>
                        <h4 class="title is-4">Class is in session! Submit your scores to see if your models make the honor roll. Professor is waiting...</h4>
                        <br>
                        <p>
                            Please remember to report your frame rate and tokens per frame with each submission.
                        </p>
                        <p>
                            Email us at <a href="mailto:enxin.23@intl.zju.edu.cn"><i class="fas fa-envelope"></i></a> or <a href="mailto:wchai@uw.edu"><i class="fas fa-envelope"></i></a>.
                        </p>
                    </div>
                    <ul class="nav nav-tabs" id="myTab" role="tablist">
                        <li class="nav-item" role="presentation">
                            <button class="nav-link active" id="main-results-tab" data-bs-toggle="tab"
                                data-bs-target="#benchmark-table-content" type="button" role="tab"
                                aria-controls="main-results-tab" aria-selected="true">Video-MMLU</button>
                        </li>
                        <!-- <li class="nav-item" role="presentation">
                            <button class="nav-link" id="eurus-code-table-tab" data-bs-toggle="tab"
                                data-bs-target="#eurus-code-table-content" type="button" role="tab"
                                aria-controls="eurus-code-table-tab" aria-selected="false">Visual Tokens Compression</button>
                        </li> -->
                    </ul>
                    <div class="tab-content" id="myTabContent">
                        <div class="tab-pane fade show active" id="benchmark-table-content" role="tabpanel"
                            aria-labelledby="benchmark-table-content">
                            <div id="behavior-benchmark-main-table"></div>
                        </div>
                        <!-- <div class="tab-pane fade" id="eurus-code-table-content" role="tabpanel"
                            aria-labelledby="eurus-code-table-content">
                            <div id="virtualhome-benchmark-main-table"></div>
                        </div> -->
                    </div>
                    <br>
                    <p>
                        We present a quantitative comparison of existing state-of-the-art large multimodal models across various multi-discipline lecture understanding tasks in Video-MMLU. 
                        # F stands for the frame sampling number of the input video, and TPF represents the visual tokens per frame. 
                        The average key frame number in Video-MMLU is 26.
                    </p>

                </div>
                <br>
                <div class="collapsible-section">
                    <button class="button is-fullwidth toggle-section" aria-controls="benchmark_table">
                        <span>View benchmark</span>
                        <span class="icon is-small">
                            <i class="fas fa-angle-down" aria-hidden="true"></i>
                        </span>
                    </button>
                    <div id="benchmark_table" class="collapse-content">
                        <iframe
                        src="https://huggingface.co/datasets/wchai/Video-Detailed-Caption/embed/viewer/default/VDC_captions"
                        frameborder="0"
                        width="100%"
                        height="560px"
                        ></iframe>
                    </div>
                </div>
                <script>
                    document.addEventListener('DOMContentLoaded', function() {
                        const button = document.querySelector('[aria-controls="benchmark_table"]');
                        if (button) {
                            button.click();
                        }
                    });
                </script>
            </div>
        </div>
    </section>


    <!-- Example video -->
    <div class="video-container carousel-enabled">
        <h2 class="title is-2" style="text-align: center;">Video-MMLU Example</h2>
        <br>
        <table style="width: 80%; margin: 0 auto;">
            <tr>
                <td style="width: 50%; padding: 10px;">
                    <video autoplay muted loop playsinline style="width: 100%; height: auto;">
                        <source src="website/videos/xgfYivQt-x0.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video> 
                    <div class="collapsible-section">
                        <button class="button is-fullwidth toggle-section" aria-controls="transition_table_vh_1">
                            <span>View lecture detailed caption of case #1</span>
                            <span class="icon is-small">
                                <i class="fas fa-angle-down" aria-hidden="true"></i>
                            </span>
                        </button>
                        <div id="transition_table_vh_1" class="collapse-content">
                            <table class="table is-striped is-hoverable" id="vh_logical_matching_score" style="width: 100%; table-layout: fixed; font-size: 0.9em;">
                                <thead>
                                    <tr> 
                                        <p>"MVPs: Wordless Animations of Five Classic Proofs without Words" presents an intricate journey through mathematical concepts using purely visual demonstrations. The video opens with a stark black background featuring the title and subtitle, accompanied by a subscribe button and thumbs-up icon, setting the stage for an engaging educational experience.</p>
                                        
                                        <p>The presentation begins with a foundational exploration of geometric series, displaying the mathematical expression \( \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \ldots + \frac{1}{2^k} + \ldots \). This infinite series is beautifully illustrated through a square divided into colored sections, where the left half is colored in deep purple representing \( \frac{1}{2} \), while the remaining space is partitioned into increasingly smaller sections in teal and purple, labeled with fractions \( \frac{1}{4} \), \( \frac{1}{8} \), \( \frac{1}{16} \), and \( \frac{1}{32} \). The visual demonstrates how these fractions collectively sum to 1, with each subsequent fraction representing half of the previous one.</p>
                                        
                                        <p>The video then transitions to exploring the sum of the first n natural numbers, presenting the equation \( 1 + 2 + 3 + \ldots + n = \frac{n(n + 1)}{2} \). This concept is visualized through a triangular arrangement of light blue squares, forming a right triangle pattern where each row contains one more square than the row above it. The dimensions are carefully labeled with n, demonstrating the relationship between the height and base of the triangle.</p>
                                        
                                        <p>A particularly elegant proof involves the difference of squares formula, \( a^2 - b^2 = (a - b)(a + b) \). This is demonstrated through multiple visual representations, including a large purple square representing \( a^2 \) and a smaller square representing \( b^2 \), with the difference illustrated through L-shaped sections and rectangular divisions. The dimensions are clearly labeled with a and b, showing how the factored form relates to the geometric representation.</p>
                                        
                                        <p>The Pythagorean theorem receives special attention through a series of illustrations, including a light blue right triangle with sides labeled a, b, and c, accompanied by the classic equation \( c^2 = a^2 + b^2 \). This is further elaborated through a square grid divided into four sections, with colored squares in purple and light blue demonstrating the relationship between the areas of squares formed by the triangle's sides.</p>
                                        
                                        <p>The presentation also explores the sum of odd numbers through the equation \( 1 + 3 + 5 + ... + (2n - 3) + (2n - 1) = n^2 \), using a grid of green and light blue squares to demonstrate how odd numbers sum to perfect squares. Each step in the progression is carefully illustrated through staircase-like arrangements of colored squares.</p>
                                        
                                        <p>Throughout the video, minimalist black silhouettes of standing figures appear at key transitions, suggesting a lecture-style presentation. A simple light bulb illustration also appears, symbolizing moments of insight or understanding. The presentation concludes by attributing these proofs to various historical figures, including ancient Greeks, Chinese mathematicians, Nicomachus of Gerasa, and Warren Page.</p>
                                        
                                        <p>Each proof is meticulously constructed using a consistent color palette of purples, blues, and teals against a black background, ensuring maximum visibility and clarity. The visual elements are carefully labeled with appropriate mathematical notation, creating a seamless blend of geometric and algebraic representations that effectively communicate complex mathematical concepts without the need for words.</p>
                                    </tr>
                                </thead>
                            </table>
                        </div>
                    </div>
                </td>
                
                <td style="width: 50%; padding: 10px;">
                    <video autoplay muted loop playsinline style="width: 100%; height: auto;">
                        <source src="website/videos/Y_w07A7chnk.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video> 
                    <div class="collapsible-section">
                        <button class="button is-fullwidth toggle-section" aria-controls="transition_table_vh_2">
                            <span>View lecture detailed caption of case #2</span>
                            <span class="icon is-small">
                                <i class="fas fa-angle-down" aria-hidden="true"></i>
                            </span>
                        </button>
                        <div id="transition_table_vh_2" class="collapse-content">
                            <table class="table is-striped is-hoverable" id="vh_logical_matching_score" style="width: 100%; table-layout: fixed; font-size: 0.9em;">
                                <thead>
                                    <tr>
                                        <p>
                                            The educational video on osmosis and tonicity, produced by Ricochet Science, presents a comprehensive exploration of these fundamental biological processes through clear visual elements and detailed explanations. 
                                            The presentation opens with a bold black title against a white background, immediately followed by the distinctive Ricochet Science logo featuring a stylized laboratory flask with rising bubbles in black and teal, establishing its educational context.
                                        </p>
                                        <p>
                                            At its core, the video establishes that osmosis represents the diffusion of water across a semipermeable membrane, while tonicity refers to the relative solute concentration between two environments separated by such a membrane. 
                                            This foundational concept is illustrated through a detailed central diagram showing a semipermeable membrane dividing two distinct environments. 
                                            The left side, labeled "Hypotonic Environment," contains a solution of 25% sodium chloride and 75% water, while the right side, labeled "Hypertonic Environment," shows 75% sodium chloride and 25% water. 
                                            The diagram uses color-coded spheres - blue for water molecules, purple for sodium ions (Na‚Å∫), and orange for chloride ions (Cl‚Åª) - to clearly demonstrate molecular composition. 
                                            Yellow arrows indicate the fundamental principle that water molecules move from the hypotonic to the hypertonic environment, always flowing toward areas of higher solute concentration.
                                        </p>
                                        <p>
                                            The presentation then explores three critical scenarios using beakers containing red blood cells in different solutions. 
                                            In the first scenario, red blood cells are suspended in pure water (a hypotonic solution). 
                                            The video explains that the cells' internal environment is hypertonic relative to the surrounding water, causing water to flow into the cells through osmosis. 
                                            This influx of water can potentially lead to cell lysis, or bursting, if sufficient water enters the cells. 
                                            The second scenario demonstrates the opposite condition, where red blood cells are placed in a hypertonic sodium chloride solution (represented by blue liquid). 
                                            This environment causes crenation, or cell shrinkage, as water moves out of the cells toward the more concentrated external solution. 
                                            The third scenario illustrates isotonic conditions, where the solution's tonicity matches that of the cells, resulting in no net water movement and maintaining cellular stability.
                                        </p>
                                        <p>
                                            Throughout the presentation, these concepts are reinforced against a gradient purple background that enhances visibility and comprehension. 
                                            The semipermeable membrane is consistently depicted as a selective barrier, allowing water passage while restricting other substances. 
                                            This selective permeability is crucial for understanding cellular homeostasis and various physiological processes, including kidney function and the effects of diseases like diabetes, which the video briefly mentions as practical applications of these principles.
                                        </p>
                                        <p>
                                            The comprehensive visual journey concludes with the Ricochet Science logo and copyright information from Ricochet Creative Productions, LLC (2013), maintaining its professional educational approach throughout. 
                                            The presentation effectively combines theoretical concepts with practical examples, helping viewers understand how osmosis and tonicity influence cellular behavior in various environmental conditions, making complex biological processes accessible to learners at different levels.
                                        </p>
                                    </tr>
                                </thead>
                            </table>
                        </div>
                    </div>
                </td>

                <td style="width: 50%; padding: 10px;">
                    <video autoplay muted loop playsinline style="width: 100%; height: auto;">
                        <source src="website/videos/6H6nCpGW1nU.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video> 
                    <div class="collapsible-section">
                        <button class="button is-fullwidth toggle-section" aria-controls="transition_table_vh_2">
                            <span>View lecture detailed caption of case #3</span>
                            <span class="icon is-small">
                                <i class="fas fa-angle-down" aria-hidden="true"></i>
                            </span>
                        </button>
                        <div id="transition_table_vh_2" class="collapse-content">
                            <table class="table is-striped is-hoverable" id="vh_logical_matching_score" style="width: 100%; table-layout: fixed; font-size: 0.9em;">
                                <thead>
                                    <tr>
                                        <p>"MVPs: Wordless Animations of Five Classic Proofs without Words" presents an intricate journey through mathematical concepts using purely visual demonstrations. The video opens with a stark black background featuring the title and subtitle, accompanied by a subscribe button and thumbs-up icon, setting the stage for an engaging educational experience.</p>
                                        
                                        <p>The presentation begins with a foundational exploration of geometric series, displaying the mathematical expression \( \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \ldots + \frac{1}{2^k} + \ldots \). This infinite series is beautifully illustrated through a square divided into colored sections, where the left half is colored in deep purple representing \( \frac{1}{2} \), while the remaining space is partitioned into increasingly smaller sections in teal and purple, labeled with fractions \( \frac{1}{4} \), \( \frac{1}{8} \), \( \frac{1}{16} \), and \( \frac{1}{32} \). The visual demonstrates how these fractions collectively sum to 1, with each subsequent fraction representing half of the previous one.</p>
                                        
                                        <p>The video then transitions to exploring the sum of the first n natural numbers, presenting the equation \( 1 + 2 + 3 + \ldots + n = \frac{n(n + 1)}{2} \). This concept is visualized through a triangular arrangement of light blue squares, forming a right triangle pattern where each row contains one more square than the row above it. The dimensions are carefully labeled with n, demonstrating the relationship between the height and base of the triangle.</p>
                                        
                                        <p>A particularly elegant proof involves the difference of squares formula, \( a^2 - b^2 = (a - b)(a + b) \). This is demonstrated through multiple visual representations, including a large purple square representing \( a^2 \) and a smaller square representing \( b^2 \), with the difference illustrated through L-shaped sections and rectangular divisions. The dimensions are clearly labeled with a and b, showing how the factored form relates to the geometric representation.</p>
                                        
                                        <p>The Pythagorean theorem receives special attention through a series of illustrations, including a light blue right triangle with sides labeled a, b, and c, accompanied by the classic equation \( c^2 = a^2 + b^2 \). This is further elaborated through a square grid divided into four sections, with colored squares in purple and light blue demonstrating the relationship between the areas of squares formed by the triangle's sides.</p>
                                        
                                        <p>The presentation also explores the sum of odd numbers through the equation \( 1 + 3 + 5 + ... + (2n - 3) + (2n - 1) = n^2 \), using a grid of green and light blue squares to demonstrate how odd numbers sum to perfect squares. Each step in the progression is carefully illustrated through staircase-like arrangements of colored squares.</p>
                                        
                                        <p>Throughout the video, minimalist black silhouettes of standing figures appear at key transitions, suggesting a lecture-style presentation. A simple light bulb illustration also appears, symbolizing moments of insight or understanding. The presentation concludes by attributing these proofs to various historical figures, including ancient Greeks, Chinese mathematicians, Nicomachus of Gerasa, and Warren Page.</p>
                                        
                                        <p>Each proof is meticulously constructed using a consistent color palette of purples, blues, and teals against a black background, ensuring maximum visibility and clarity. The visual elements are carefully labeled with appropriate mathematical notation, creating a seamless blend of geometric and algebraic representations that effectively communicate complex mathematical concepts without the need for words.</p>
                                    </tr>
                                </thead>
                            </table>
                        </div>
                    </div>
                </td>

                <td style="width: 50%; padding: 10px;">
                    <video autoplay muted loop playsinline style="width: 100%; height: auto;">
                        <source src="website/videos/JQNtR8lqcHA.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video> 
                    <div class="collapsible-section">
                        <button class="button is-fullwidth toggle-section" aria-controls="transition_table_vh_2">
                            <span>View lecture detailed caption of case #4</span>
                            <span class="icon is-small">
                                <i class="fas fa-angle-down" aria-hidden="true"></i>
                            </span>
                        </button>
                        <div id="transition_table_vh_2" class="collapse-content">
                            <table class="table is-striped is-hoverable" id="vh_logical_matching_score" style="width: 100%; table-layout: fixed; font-size: 0.9em;">
                                <thead>
                                    <tr>
                                        <p>The video presents a sophisticated mathematical exploration of the expression ‚àö101 - ‚àö99, demonstrating an elegant approach to approximating the difference between two closely spaced square roots. Against a clean white background, a friendly cartoon character wearing glasses and a graduation cap serves as a mathematical guide, establishing the video's educational tone from the outset.</p>

                                        <p>The presentation begins with a crucial insight into the rationalization process, emphasizing that this technique is essential for such expressions involving the difference of square roots. The video methodically demonstrates the rationalization by multiplying both numerator and denominator by (‚àö101 + ‚àö99), a strategic step that transforms the expression into (‚àö101 - ‚àö99)(‚àö101 + ‚àö99) / (‚àö101 + ‚àö99). This manipulation leverages the fundamental difference of squares formula, (a + b)(a - b) = a¬≤ - b¬≤, which appears highlighted in red to underscore its pivotal role. The numerator elegantly simplifies to 101 - 99 = 2, yielding the more manageable form 2/(‚àö101 + ‚àö99).</p>

                                        <p>The exploration then delves into a sophisticated analysis of bounds and properties. The video introduces the variable x to represent ‚àö101 + ‚àö99, and through careful algebraic manipulation, demonstrates that x¬≤ = 200 + 2‚àö(100¬≤ - 1). This leads to a critical insight: since 100¬≤ - 1 represents numbers very close to 100¬≤, the expression can be bounded between 398 and 400. Through rigorous mathematical reasoning, the video establishes that x must lie between 19 and 20, as x¬≤ < 400 (20¬≤ = 400) and x¬≤ > 361 (19¬≤ = 361).</p>

                                        <p>The presentation further enriches understanding by showing how (‚àö101 + ‚àö99)¬≤ expands to 101 + 99 + 2‚àö(101 √ó 99), demonstrating the interconnection between different algebraic forms. This expansion provides additional verification of the bounds previously established. The analysis culminates in proving that 2/x falls within the precise range of 0.1 < 2/x < 0.105, leading to the approximate value of ‚àö101 - ‚àö99 ‚âà 0.1025.</p>

                                        <p>Throughout the demonstration, visual aids enhance comprehension, with red arrows and color-coded inequalities guiding viewers through the mathematical relationships. A playful gray cat makes an endearing appearance, raising its paw in a friendly gesture, providing a moment of levity amidst the technical content. The video maintains its engaging approach while systematically building upon each concept, ensuring viewers grasp both the mathematical mechanics and the underlying reasoning.</p>

                                        <p>The presentation concludes with a visually appealing closing frame, featuring a red "SUBSCRIBE" button in the top left corner alongside a notification bell icon. The word "thank you" appears in artistic purple and red lettering, incorporating a heart symbol, while a cartoonish blue hand makes an appreciative gesture against the white background. This thoughtful conclusion maintains the video's welcoming tone while reinforcing its educational value.</p>

                                        <p>The entire presentation successfully combines rigorous mathematical analysis with accessible visual elements, making complex algebraic concepts more approachable while maintaining mathematical precision throughout the step-by-step exploration of transforming and bounding the expression ‚àö101 - ‚àö99.</p>
                                    </tr>
                                </thead>
                            </table>
                        </div>
                    </div>
                </td>

                <td style="width: 50%; padding: 10px;">
                    <video autoplay muted loop playsinline style="width: 100%; height: auto;">
                        <source src="website/videos/DyKU__ivYm0.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video> 
                    <div class="collapsible-section">
                        <button class="button is-fullwidth toggle-section" aria-controls="transition_table_vh_2">
                            <span>View lecture detailed caption of case #5</span>
                            <span class="icon is-small">
                                <i class="fas fa-angle-down" aria-hidden="true"></i>
                            </span>
                        </button>
                        <div id="transition_table_vh_2" class="collapse-content">
                            <table class="table is-striped is-hoverable" id="vh_logical_matching_score" style="width: 100%; table-layout: fixed; font-size: 0.9em;">
                                <thead>
                                    <tr>
                                        <p>In this detailed mathematical video presentation, we observe a young man seated in front of a light-colored wall with windows, wearing a distinctive plaid shirt and baseball cap throughout. He engages enthusiastically with his audience while explaining an intricate geometric problem involving three circles and their relationships within a rectangular boundary. His recent haircut, which he playfully mentions at the end, adds a personal touch to his professional demeanor.</p>

                                        <p>The main problem, prominently displayed with the heading "Can you solve it?" and accompanied by a star icon, features three circles with diameters labeled as 3, 4, and 6 units. These circles are arranged within a rectangular framework, with the largest circle (diameter 6) determining the height of the rectangle. The problem's elegant setup demonstrates how these circles are tangent to each other and the rectangle's boundaries, creating an interesting geometric relationship that requires careful analysis to solve.</p>

                                        <p>The instructor methodically develops the solution by first breaking down the unknown distance into two components, labeled as x and y. This decomposition proves crucial for solving the problem, as it allows for the application of the Pythagorean theorem to two separate right triangles. The circles' radii (1.5, 2, and 3 units respectively) play a fundamental role in establishing these relationships.</p>

                                        <p>Throughout the video, the instructor develops the solution using several complementary diagrams. One diagram shows the circles with additional markings, including a fraction (2/6) and various dimensions labeled as 1.5, 3, 5, and 2. The problem is further elaborated using color-coding, with purple and green sections highlighting different parts of the solution path. Blue dashed lines indicate radii and measurements between key points, helping viewers follow the geometric reasoning.</p>

                                        <p>The solution process involves multiple geometric and algebraic steps, beginning with the analysis of the two larger circles. A right triangle is introduced with sides labeled 1 and 5, leading to the Pythagorean theorem equation: 1¬≤ + y¬≤ = 5¬≤. This is followed by the simplification 1 + y¬≤ = 25, ultimately yielding y = 2‚àö6. Another key calculation involves a right triangle with sides of 2.5 and 3.5 units, utilized to determine the value of x through the equation 2.5¬≤ + x¬≤ = 3.5¬≤, which leads to x = ‚àö6.</p>

                                        <p>As the solution progresses, various measurements are revealed and analyzed, including segments marked as ‚àö6 and 2‚àö6. The instructor carefully explains the relationships between these measurements, using vertical and horizontal lines to demonstrate connections. Green lines are employed to highlight specific measurements, particularly when dealing with the length marked as 5 units and the variable y.</p>

                                        <p>The mathematical working shows particular attention to detail in handling square roots and simplification. The process of simplifying ‚àö24 into 2‚àö6 is clearly explained, demonstrating important algebraic techniques. The final solution elegantly combines the two components (x + y) to arrive at 3‚àö6, which represents the total distance in question.</p>

                                        <p>The video culminates with the complete solution, showing how all the geometric relationships and measurements come together. The final diagrams display both the initial problem setup and the solved configuration, with all relevant measurements clearly labeled, including the conclusive proof that the unknown length equals 3‚àö6. The instructor's animated and friendly demeanor helps maintain viewer engagement throughout this complex mathematical journey, all while staying in his consistent position in front of the light-colored wall with windows visible in the background. His step-by-step approach, combined with clear visual aids and enthusiastic presentation style, makes this challenging geometric problem accessible and engaging for viewers.</p>
                                    </tr>
                                </thead>
                            </table>
                        </div>
                    </div>
                </td>

                <td style="width: 50%; padding: 10px;">
                    <video autoplay muted loop playsinline style="width: 100%; height: auto;">
                        <source src="website/videos/rbJlTAO_Oms.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video> 
                    <div class="collapsible-section">
                        <button class="button is-fullwidth toggle-section" aria-controls="transition_table_vh_2">
                            <span>View lecture detailed caption of case #6</span>
                            <span class="icon is-small">
                                <i class="fas fa-angle-down" aria-hidden="true"></i>
                            </span>
                        </button>
                        <div id="transition_table_vh_2" class="collapse-content">
                            <table class="table is-striped is-hoverable" id="vh_logical_matching_score" style="width: 100%; table-layout: fixed; font-size: 0.9em;">
                                <thead>
                                    <tr>
                                        <p>"THIS IS MF DOOM" presents an intricate mathematical exploration set against a stark black background, where complex mathematical concepts are woven together with cultural references to the legendary rapper and producer MF DOOM. Throughout the presentation, a bold title consistently anchors each frame, serving as a reminder of the unique intersection between mathematics and musical artistry.</p>

                                        <p>The video begins by introducing a fundamental mathematical series, presenting the expression (1 - p) + p(1 - p) + p¬≤(1 - p) + p¬≥(1 - p) + ..., which equals 1. This foundational series emerges from a recursive process of repeatedly dividing the rightmost piece into fixed proportions, demonstrating how mathematical patterns can arise from simple iterative procedures. The related geometric series 1 + p + p¬≤ + p¬≥ + ... simplifies to 1/(1 - p), a crucial result that underlies much of the subsequent analysis. The presentation carefully explains that this series "makes sense for almost any value of p," though the initial derivation only applies for values between 0 and 1.</p>

                                        <p>A significant portion of the video focuses on a probability distribution displayed on a number line ranging from 0 to 1. The line features crucial expressions involving the variable p and its complement (1 - p), with specific attention paid to terms like (1 - p), p(1 - p), p¬≤(1 - p), p¬≥(1 - p), and p‚Å¥. Arrows strategically point to these expressions, emphasizing their relationships and significance within the probability framework. This visual representation helps illustrate how the series components distribute across the unit interval.</p>

                                        <p>The presentation then delves into alternating series, examining the behavior of (-1)‚Å∞ + (-1)¬π + (-1)¬≤ + (-1)¬≥ + ..., which equals 1/(1 - (-1)). This leads to the fascinating result that the alternating series 1 - 1 + 1 - 1 + ... equals ¬Ω, a result that, while seemingly counterintuitive, emerges naturally from the established framework. Further mathematical exploration introduces the geometric series 2‚Å∞ + 2¬π + 2¬≤ + 2¬≥ + ..., which equals 1/(1-2), demonstrating how 1 + 2 + 4 + 8 + ... surprisingly equals -1. These results showcase how mathematical formalism can lead to unexpected yet consistent conclusions when extended beyond their original context.</p>

                                        <p>The video maintains its mathematical rigor while illustrating these concepts through various representations. Each frame builds upon the previous, creating a cohesive narrative that connects probability theory, infinite series, and geometric progressions. The representation of these concepts includes both algebraic expressions and visual elements on the number line, making complex mathematical ideas more accessible.</p>

                                        <p>Throughout the presentation, special attention is paid to the variable p and its various powers and combinations with (1 - p), suggesting a deeper connection between probability theory and the artistic themes associated with MF DOOM. The consistent use of the black background with white text creates a stark contrast that emphasizes the mathematical notation while maintaining a stylistic connection to the artist's aesthetic.</p>

                                        <p>The video concludes by reinforcing these mathematical relationships, particularly focusing on the probability distribution and infinite series concepts. The final frames reiterate the key expressions and their relationships, ensuring viewers grasp both the individual components and their interconnections within the larger mathematical framework, all while maintaining the thematic connection to MF DOOM's artistic legacy. The presentation demonstrates how mathematical formulas can transcend their original derivation contexts to reveal broader patterns and relationships in unexpected domains.</p>
                                    </tr>
                                </thead>
                            </table>
                        </div>
                    </div>
                </td>
            </tr>
        </table>
    </div>


    <!-- Abstract. -->
    <section class="section" id="abstract">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-2">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Recent advancements in language multimodal models (LMMs) for video have demonstrated their potential for understanding video content, yet the task of comprehending multi-discipline lectures remains largely unexplored. 
                            We introduce Video-MMLU, a massive benchmark designed to evaluate the capabilities of LMMs in understanding Multi-Discipline Lectures. 
                            We evaluate over 90 open-source and proprietary models, ranging from 0.5B to 40B parameters. 
                            Our results highlight the limitations of current models in addressing the cognitive challenges presented by these lectures, especially in tasks requiring both perception and reasoning. 
                            Additionally, we explore how the number of visual tokens and the large language models influence performance, offering insights into the interplay between multimodal perception and reasoning in lecture comprehension.
                        </p>
                    </div>
                </div>
            </div>

        </div>
    </section>


    <!-- Method -->
    <section class="section" id="embodied_agent_interface_detail">
        <div class="container is-max-desktop">
            <div class="hero-body">
                    <h2 class="title is-2" style="text-align: center;">AuroraCap: A Efficient and Performant Video Detailed Captioner</h2>
                    <br>
                    <div class="content has-text-justified">
                        <h3 class="title is-4">Architecture</h3>
                        <p>
                            <strong>LLaVA.<d-cite key="liu2024visual"></d-cite></strong> 
                            To effectively leverage the capabilities of both the pre-trained LLM and visual model, LLaVA adapt a simple multilayer perceptron (MLP) projection layer to connect each patch tokens of image features into the word embedding space. 
                        </p>
                        <p>
                            <strong>Token merging.<d-cite key="bolya2022token"></d-cite></strong> 
                            To increase the throughput of existing ViT models, Token Merging is proposed to gradually combines similar tokens in a transformer to reduce the number of tokens passing through ViT models. 
                            Token Merging has been proven to be effective on image and video classification tasks even without the need for training.
                            We conduct frame-wise token merging in AuroraCap, where the feature is extracted by CLIP ViT-H<d-cite key="fang2023data"></d-cite> model. 
                            We show token merging visualization examples from  COCO<d-cite key="lin2014microsoft"></d-cite>, VG<d-cite key="krishna2017visual"></d-cite>, SA-1B<d-cite key="kirillov2023segment"></d-cite> as follows:
                            <d-figure>
                                <figure class="l-body">
                                    <div id='tomevis_div'></div>
                                    <script src="https://d3js.org/d3.v7.min.js"></script>
                                    <script src="website/javascript/tome_vis.js"></script>
                                    <figcaption>
                                        Token merging visualization. From left to right, the number of visual tokens representing the images are 490, 154, 18, and 6.
                                    </figcaption>
                                    </figure>
                            </d-figure>
                        </p>
                        <br>
                        <h3 class="title is-4">Training Recipe</h3>
                        <p>
                            We use over 20 million high-quality image/video-text pairs to train AuroraCap in three stages. The training datasets are released at <a href="https://huggingface.co/datasets/Reself/AuroraCap-trainset" target="_blank">HuggingFace</a>.
                        </p>
                        <p>
                            <strong>Pretraining stage.</strong> 
                            We first align visual features with the word embedding space of LLMs. 
                            To achieve this, we freeze the pretrained ViT and LLM, training solely the vision-language connector. 
                        </p>
                        <p>
                            <strong>Vision stage.</strong> 
                            We unfreeze the pretrained ViT while freezing the LLM during vision stage and train with the public data among various computer vision tasks to get better generalization.
                        </p>
                        <p>
                            <strong>Language stage.</strong> 
                            Finally, we conduct end-to-end training, which means all the components are trainable, with the most high-quality public data during language stage. 
                        </p>
                        <div class="collapsible-section">
                            <button class="button is-fullwidth toggle-section" aria-controls="transition_table_vh_3">
                                <span>View traiset of AuroraCap</span>
                                <span class="icon is-small">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </span>
                            </button>
                            <div id="transition_table_vh_3" class="collapse-content">
                                <iframe
                                src="https://huggingface.co/datasets/wchai/AuroraCap-trainset/embed/viewer/default/projection"
                                frameborder="0"
                                width="100%"
                                height="560px"
                                ></iframe>
                            </div>
                        </div>
                        <script>
                            document.addEventListener('DOMContentLoaded', function() {
                                const button = document.querySelector('[aria-controls="transition_table_vh_3"]');
                                if (button) {
                                    button.click();
                                }
                            });
                        </script>
                    </div>
            </div>
        </div>
    </section>


    <!-- Benchmark -->
    <section class="section" id="embodied_agent_interface_detail">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <h2 class="title is-2" style="text-align: center;">VDC: A New Video Detailed Captioning Benchmark</h2>
                <br>
                <div class="content has-text-justified">
                    <h3 class="title is-4">Benchmark Collection and Processing</h3>
                    <p>
                        <strong>Video collection and processing.</strong>
                        We building VDC upon Panda-70M<d-cite key="chen2024panda"></d-cite>, Ego4D<d-cite key="grauman2022ego4d"></d-cite>, Mixkit<d-cite key="mixkit"></d-cite>, Pixabay<d-cite key="pixabay"></d-cite>, and Pexels<d-cite key="pexels"></d-cite>. 
                        We first split the video into clips and apply dense frame extraction, then manually replacing blurry frames with adjacent clear ones.
                        <div class="collapsible-section">
                            <button class="button is-fullwidth toggle-section" aria-controls="model_table">
                                <span>View benchmark comparison for video captioning task</span>
                                <span class="icon is-small">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </span>
                            </button>
                            <div id="model_table" class="collapse-content">
                                <table class="table is-striped is-hoverable" id="model_info">
                                    <caption style="caption-side: top; text-align: center; color: black; font-style: italic;">
                                        <b>Table 1 :</b> Benchmark comparison for video captioning task. Ave. Length indicates the average number of words per caption.
                                    </caption>
                                    <thead>
                                        <tr>
                                            <th class="tb-hdr">Dataset</th>
                                            <th>Theme</th>
                                            <th style="text-align: center; vertical-align: middle;"># Video</th>
                                            <th style="text-align: center; vertical-align: middle;"># Clip</th>
                                            <th style="text-align: center; vertical-align: middle;"># Caption</th>
                                            <th style="text-align: center; vertical-align: middle;"># Word</th>
                                            <th style="text-align: center; vertical-align: middle;"># Vocab.</th>
                                            <th style="text-align: center; vertical-align: middle;">Ave. Length</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td class="italic">MSVD<d-cite key="chen2011collecting"></d-cite></td>
                                            <td style="text-align: center; vertical-align: middle;">Open</td>
                                            <td style="text-align: center; vertical-align: middle;">1,970</td>
                                            <td style="text-align: center; vertical-align: middle;">1,970</td>
                                            <td style="text-align: center; vertical-align: middle;">70,028</td>
                                            <td style="text-align: center; vertical-align: middle;">607,339</td>
                                            <td style="text-align: center; vertical-align: middle;">13,010</td>
                                            <td style="text-align: center; vertical-align: middle;">8.67</td>
                                        </tr>
                                        <tr>
                                            <td class="italic">MSR-VTT<d-cite key="xu2016msr"></d-cite></td>
                                            <td style="text-align: center; vertical-align: middle;">Open</td>
                                            <td style="text-align: center; vertical-align: middle;">7,180</td>
                                            <td style="text-align: center; vertical-align: middle;">10,000</td>
                                            <td style="text-align: center; vertical-align: middle;">200,000</td>
                                            <td style="text-align: center; vertical-align: middle;">1,856,523</td>
                                            <td style="text-align: center; vertical-align: middle;">29,316</td>
                                            <td style="text-align: center; vertical-align: middle;">9.28</td>
                                        </tr>
                                        <tr>
                                            <td class="italic">ActivityNet<d-cite key="krishna2017dense"></d-cite></td>
                                            <td style="text-align: center; vertical-align: middle;">Open</td>
                                            <td style="text-align: center; vertical-align: middle;">20,000</td>
                                            <td style="text-align: center; vertical-align: middle;">100,000</td>
                                            <td style="text-align: center; vertical-align: middle;">100,000</td>
                                            <td style="text-align: center; vertical-align: middle;">1,340,000</td>
                                            <td style="text-align: center; vertical-align: middle;">15,564</td>
                                            <td style="text-align: center; vertical-align: middle;">13.40</td>
                                        </tr>
                                        <tr>
                                            <td class="italic">S-MiT<d-cite key="monfort2021spoken"></d-cite></td>
                                            <td style="text-align: center; vertical-align: middle;">Open</td>
                                            <td style="text-align: center; vertical-align: middle;">515,912</td>
                                            <td style="text-align: center; vertical-align: middle;">515,912</td>
                                            <td style="text-align: center; vertical-align: middle;">515,912</td>
                                            <td style="text-align: center; vertical-align: middle;">5,618,064</td>
                                            <td style="text-align: center; vertical-align: middle;">50,570</td>
                                            <td style="text-align: center; vertical-align: middle;">10.89</td>
                                        </tr>
                                        <tr>
                                            <td class="italic">M-VAD<d-cite key="torabi2015using"></d-cite></td>
                                            <td style="text-align: center; vertical-align: middle;">Movie</td>
                                            <td style="text-align: center; vertical-align: middle;">92</td>
                                            <td style="text-align: center; vertical-align: middle;">48,986</td>
                                            <td style="text-align: center; vertical-align: middle;">55,905</td>
                                            <td style="text-align: center; vertical-align: middle;">519,933</td>
                                            <td style="text-align: center; vertical-align: middle;">18,269</td>
                                            <td style="text-align: center; vertical-align: middle;">9.30</td>
                                        </tr>
                                        <tr>
                                            <td class="italic">MPII-MD<d-cite key="rohrbach2013translating"></d-cite></td>
                                            <td style="text-align: center; vertical-align: middle;">Movie</td>
                                            <td style="text-align: center; vertical-align: middle;">94</td>
                                            <td style="text-align: center; vertical-align: middle;">68,337</td>
                                            <td style="text-align: center; vertical-align: middle;">68,375</td>
                                            <td style="text-align: center; vertical-align: middle;">653,467</td>
                                            <td style="text-align: center; vertical-align: middle;">24,549</td>
                                            <td style="text-align: center; vertical-align: middle;">9.56</td>
                                        </tr>
                                        <tr>
                                            <td class="italic">Youcook2<d-cite key="zhou2018towards"></d-cite></td>
                                            <td style="text-align: center; vertical-align: middle;">Cooking</td>
                                            <td style="text-align: center; vertical-align: middle;">2,000</td>
                                            <td style="text-align: center; vertical-align: middle;">15,400</td>
                                            <td style="text-align: center; vertical-align: middle;">15,400</td>
                                            <td style="text-align: center; vertical-align: middle;">121,418</td>
                                            <td style="text-align: center; vertical-align: middle;">2,583</td>
                                            <td style="text-align: center; vertical-align: middle;">7.88</td>
                                        </tr>
                                        <tr>
                                            <td class="italic">Charades<d-cite key="sigurdsson2016hollywood"></d-cite></td>
                                            <td style="text-align: center; vertical-align: middle;">Human</td>
                                            <td style="text-align: center; vertical-align: middle;">9,848</td>
                                            <td style="text-align: center; vertical-align: middle;">10,000</td>
                                            <td style="text-align: center; vertical-align: middle;">27,380</td>
                                            <td style="text-align: center; vertical-align: middle;">607,339</td>
                                            <td style="text-align: center; vertical-align: middle;">13,000</td>
                                            <td style="text-align: center; vertical-align: middle;">22.18</td>
                                        </tr>
                                        <tr>
                                            <td class="italic">VATEX<d-cite key="wang2019vatex"></d-cite></td>
                                            <td style="text-align: center; vertical-align: middle;">Open</td>
                                            <td style="text-align: center; vertical-align: middle;">41,300</td>
                                            <td style="text-align: center; vertical-align: middle;">41,300</td>
                                            <td style="text-align: center; vertical-align: middle;">413,000</td>
                                            <td style="text-align: center; vertical-align: middle;">4,994,768</td>
                                            <td style="text-align: center; vertical-align: middle;">44,103</td>
                                            <td style="text-align: center; vertical-align: middle;">12.09</td>
                                        </tr>
                                        <tr>
                                            <td class="italic">VDC (ours)</td>
                                            <td style="text-align: center; vertical-align: middle;">Open</td>
                                            <td style="text-align: center; vertical-align: middle;">1,027</td>
                                            <td style="text-align: center; vertical-align: middle;">1,027</td>
                                            <td style="text-align: center; vertical-align: middle;">1,027</td>
                                            <td style="text-align: center; vertical-align: middle;">515,441</td>
                                            <td style="text-align: center; vertical-align: middle;">20,419</td>
                                            <td class="highlight-red" style="text-align: center; vertical-align: middle;">500.91</td>
                                        </tr>
                                    </tbody>
                                </table>
                            </div>
                        </div>
                        <script>
                            document.addEventListener('DOMContentLoaded', function() {
                                const button = document.querySelector('[aria-controls="model_table"]');
                                if (button) {
                                    button.click();
                                }
                            });
                        </script>
                    </p>
                    <p>
                        <strong>Structured detailed captions construction pipeline.</strong>
                        We develop a structured detailed captions construction pipeline to generate extra detailed descriptions from various perspectives, significantly extending the length and enhancing the richness compared to previous benchmarks. 
                        The structured detailed captions includes camera, short, background, main object, and detailed captions.
                        <div class="collapsible-section">
                            <button class="button is-fullwidth toggle-section" aria-controls="transition_table_vh_5">
                                <span>View definition of structured detailed captions</span>
                                <span class="icon is-small">
                                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                                </span>
                            </button>
                            <div id="transition_table_vh_5" class="collapse-content">
                                <ol style="margin-left: 20px;">
                                    <li style="margin-bottom: 3px;"><strong>Camera caption.</strong>
                                        Describe the camera work in detail, including shot types, angles, movements, transitions, and any special effects used to enhance the video.
                                    </li>
                                    <li style="margin-bottom: 3px;"><strong>Short caption.</strong>
                                        Summarize the video in one detailed sentence, capturing key actions and the overall mood.
                                    </li>
                                    <li style="margin-bottom: 3px;"><strong>Background caption.</strong>
                                        Provide a detailed description of the background, including objects, location, weather, time, and any dynamic elements.
                                    </li>
                                    <li style="margin-bottom: 3px;"><strong>Main Object caption.</strong>
                                        Give a thorough description of the main subject's actions, attributes, interactions, and movements throughout the video frames.
                                    </li>
                                    <li style="margin-bottom: 3px;"><strong>Detailed caption.</strong>
                                        Generate a detailed, vivid caption for the video, covering all categories, ensuring it's engaging, informative, and rich enough for AI to recreate the video content.
                                    </li>
                                </ol>
                            </div>
                        </div>
                        <script>
                            document.addEventListener('DOMContentLoaded', function() {
                                const button = document.querySelector('[aria-controls="transition_table_vh_5"]');
                                if (button) {
                                    button.click();
                                }
                            });
                        </script>
                        
                    </p>
                    <p>
                        To generate detailed, fine-grained, and accurate captions, we leverage GPT-4o to produce video descriptions. 
                        We design a hierarchical prompt strategy to efficiently obtain accurate structured captions and detailed captions in two conversation rounds: (1) Structured Captions Generation and (2) Detailed Captions Integration. 
                    </p>
                    <br>
                    <d-figure id="fig-vision_connector">
                        <figure>
                            <img data-zoomable="" draggable="false" src="website/img/vdc.png" alt="Video length in VDC" style="width: 80%;display: block; margin: 0 auto;">
                            <figcaption>
                                Distribution of the video length and structured caption length in VDC.
                            </figcaption>
                        </figure>
                    </d-figure>
                </div>
                <div class="content has-text-justified">
                    <h3 class="title is-4">VDCscore: Evaluating Detailed Captions with LLMs</h3>
                    <p>
                        We introduce VDCscore, a novel quantitative metric that utilizes LLMs to evaluate the similarity between predicted and ground-truth detailed captions through a divide-and-conquer approach. 
                        The core idea of VDCscore is to decompose long detailed captions into multiple short question-answering pairs, avergae the evaluation of each pair as the final result.
                    </p>
                    <d-figure id="fig-vision_connector"></d-figure>
                        <figure>
                            <img data-zoomable="" draggable="false" src="website/img/vdcscore.png" alt="" style="width: 80%;display: block; margin: 0 auto;">
                            <figcaption>
                                VDCscore evaluation pipeline.
                            </figcaption>
                        </figure>
                    </d-figure>
                </div>
            </div>
        </div>
    </section>


    <!-- Evaluation-->
    <section class="section" id="embodied_agent_interface_detail">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <h2 class="title is-2" style="text-align: center;">Evaluation</h2>
                <br>
                <div class="content has-text-justified">
                    <h3 class="title is-4">Benchmarking video detailed captioning.</h3>
                    <p>
                        AuroraCap achieves superior performance in video detailed captioning while utilizing significantly fewer visual tokens than other models, fully highlighting the efficiency of AuroraCap.
                    </p>
                    <d-figure id="fig-vision_connector">
                        <figure>
                            <img data-zoomable="" draggable="false" src="website/img/vdc_benchmark.png" alt="Video length in VDC" style="width: 80%;display: block; margin: 0 auto;">
                            <figcaption>
                                Comparison between various models with different number of visual tokens input on VDC.
                            </figcaption>
                        </figure>
                    </d-figure>
                </div>
            </div>
        </div>
    </section>

    
    <!-- Ablation Study -->
    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <h3 class="title is-3">Ablation Study</h3>
                <p>
                    As a core training and inference strategy of AuroraCap, token merging plays a significant role in reducing the number of visual tokens. 
                    We further study how the video detailed captioning capability is influenced by token merge ratio.
                </p>
                <d-figure id="fig-vision_connector">
                    <figure>
                        <img data-zoomable="" draggable="false" src="website/img/tome.png" alt="Ablation study" style="width: 80%;display: block; margin: 0 auto;">
                        <figcaption>
                            Visualization of token merging ratio on various image and video understanding tasks. 
                            The solid line indicates the average performance across various tasks, and the shaded area represents performance variability. 
                        </figcaption>
                    </figure>
                </d-figure>
                <br>
                <p>
                    We define the performance percentage as the proportion between the highest and lowest values on the entire performance curve. 
                    We highlight the token merging ratio when achieving 90% and 80% performance with the dash line and filled area. 
                    We found that token merging significantly reduces the number of tokens while maintaining minimal performance drop, and even showing improvement in some tasks. 
                </p>
                <div class="collapsible-section">
                    <button class="button is-fullwidth toggle-section" aria-controls="vis_ablation">
                        <span>View token merging ratio curve on various tasks.</span>
                        <span class="icon is-small">
                            <i class="fas fa-angle-down" aria-hidden="true"></i>
                        </span>
                    </button>
                    <div id="vis_ablation" class="collapse-content">
                        <d-figure>
                            <figure class="l-body">
                                <div id="singlecurve_div">
                                    <div id="single_curve">
                                        <script src="website/javascript/single_curve.js"></script>
                                    </div>
                                </div>
                                <figcaption>
                                    Ablation study on token merging ratio on various image and video understanding tasks.
                                </figcaption>
                            </figure>
                        </d-figure>
                    </div>
                </div>
                <br>
                <p>
                    To assess the inference speed, we utilize the inference time per video question-answering pair in seconds (TPV) as an evaluative metric. 
                    Figure below indicates the minimum TPV achievable in our settings including with or without token merging and SGLang across seven video understanding datasets. 
                    Reducing the visual tokens and using SGLang result in excellent inference times per video question-answering pair while all the datasets with short video and question inputs. 
                </p>
                <d-figure id="fig-vision_connector">
                    <figure>
                        <img data-zoomable="" draggable="false" src="website/img/sglang.png" alt="Video length in VDC" style="width: 80%;display: block; margin: 0 auto;">
                        <figcaption>
                            Comparison between different inference settings: 
                            <b>A</b>: R<sub>vtk</sub> = 1.0</span>, without SGLang, 
                            <b>B</b>: R<sub>vtk</sub> = 0.1</span>, without SGLang, 
                            <b>C</b>: R<sub>vtk</sub> = 1.0</span>, with SGLang, 
                            <b>D</b>: R<sub>vtk</sub> = 0.1</span>, with SGLang. 
                            The number indicates the maximum inference time in seconds for each benchmark.
                        </figcaption>
                    </figure>
                </d-figure>
            </div>
        </div>
    </section>


    <!-- Previous work -->
    <h2 class="title is-2" style="text-align: center;">Our Related Work</h2>
    <section class="section" id="related_work" style="border: 2px dashed #ccc; border-radius: 8px; padding: 5px; margin: 5px auto; max-width: 50%;">  
        <div class="container" style="max-width: 100%;">
            <div class="hero-body" style="padding: 5px;">
                <div class="has-text-centered">
                    <h5 style="font-weight: bold; margin: 3px 0;">
                        MovieChat: From Dense Token to Sparse Memory for Long Video Understanding
                    </h5>
                    <p style="color: hsl(271, 100%, 27%); font-weight: bold; text-align: center; margin: 3px 0;">The first long-form video open-ended benchmark.</p>
                    <div class="'is-size-4 publication-authors">
                        <span class="author-block" style="color: darkred; font-weight: bold;">CVPR 2024</span>
                    </div>
                </div>
                <div class="content has-text-justified">
                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- Paper Link. -->
                            <span class="link-block">
                                <a href="https://arxiv.org/abs/2307.16449v4" class="btn btn-outline-dark"
                                    role="button">
                                    <span class="icon">
                                        <i class="ai ai-arxiv"></i>
                                    </span>
                                    <span>arXiv</span>
                                </a> &nbsp;&nbsp;
                            </span>

                            <!-- Leaderboard Link. -->
                            <span class="link-block">
                                <a href="https://github.com/rese1f/MovieChat?tab=readme-ov-file#-moviechat-1k-leaderboard" class="btn btn-outline-dark"
                                    role="button">
                                    <span class="icon">
                                        <i class="fab fa-github"></i>
                                    </span>
                                    <span>Leaderboard</span>
                                </a> &nbsp;&nbsp;
                            </span>

                            <!-- Benchmark Link. -->
                            <span class="link-block">
                                <a href="https://huggingface.co/datasets/Enxin/MovieChat-1K-test" class="btn btn-outline-dark" role="button" style="display: inline-flex; align-items: center;">
                                    <span class="icon" style="display: inline-flex; align-items: center;">
                                        <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face" style="width: 20px; height: 18px; margin-right: 5px;">
                                    </span>
                                    <span>MovieChat-1K Benchmark</span>
                                </a> &nbsp;&nbsp;
                            </span>

                            <!-- Code Link. -->
                            <span class="link-block">
                                <a href="https://github.com/rese1f/MovieChat" class="btn btn-outline-dark" role="button">
                                    <span class="icon">
                                        <i class="fab fa-github"></i>
                                    </span>
                                    <span>Code</span>
                                </a> &nbsp;&nbsp;

                            </span>
                                                                                
                        </div>
                    </div>
                    
                </div>
            </div>
        </div>
    </section>
    <section class="section" id="related_work" style="border: 2px dashed #ccc; border-radius: 8px; padding: 5px; margin: 5px auto; max-width: 50%;">  
        <div class="container" style="max-width: 100%;">
            <div class="hero-body" style="padding: 5px;">
                <div class="has-text-centered">
                    <h5 style="font-weight: bold; margin: 3px 0;">
                        AuroraCap: Efficient, Performant Video Detailed Captioning and a New Benchmark
                    </h5>
                    <p style="color: hsl(271, 100%, 27%); font-weight: bold; text-align: center; margin: 3px 0;">A more efficient multimodal large language model series.
                    <div class="'is-size-4 publication-authors">
                        <span class="author-block" style="color: darkred; font-weight: bold;">ICLR 2025</span>
                    </div>
                </div>
                <div class="content has-text-justified">
                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- Paper Link. -->
                            <span class="link-block">
                                <a href="https://arxiv.org/abs/2410.03051" class="btn btn-outline-dark"
                                    role="button">
                                    <span class="icon">
                                        <i class="ai ai-arxiv"></i>
                                    </span>
                                    <span>arXiv</span>
                                </a> &nbsp;&nbsp;
                            </span>

                            <!-- Leaderboard Link. -->
                            <span class="link-block">
                                <a href="https://rese1f.github.io/aurora-web/" class="btn btn-outline-dark"
                                    role="button">
                                    <span class="icon">
                                        <i class="fab fa-github"></i>
                                    </span>
                                    <span>Website</span>
                                </a> &nbsp;&nbsp;
                            </span>

                            <!-- Model Link. -->
                            <span class="link-block">
                                <a href="https://huggingface.co/collections/wchai/auroracap-66d117ffe13bedda96702013" class="btn btn-outline-dark" role="button" style="display: inline-flex; align-items: center;">
                                    <span class="icon" style="display: inline-flex; align-items: center;">
                                        <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face" style="width: 20px; height: 18px; margin-right: 5px;">
                                    </span>
                                    <span>AuroraCap Model</span>
                                </a> &nbsp;&nbsp;
                            </span>

                            <!-- Benchmark Link. -->
                            <span class="link-block">
                                <a href="https://huggingface.co/datasets/wchai/Video-Detailed-Caption" class="btn btn-outline-dark" role="button" style="display: inline-flex; align-items: center;">
                                    <span class="icon" style="display: inline-flex; align-items: center;">
                                        <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" alt="Hugging Face" style="width: 20px; height: 18px; margin-right: 5px;">
                                    </span>
                                    <span>VDC Benchmark</span>
                                </a> &nbsp;&nbsp;
                            </span>

                            <!-- Code Link. -->
                            <span class="link-block">
                                <a href="https://github.com/rese1f/aurora" class="btn btn-outline-dark" role="button">
                                    <span class="icon">
                                        <i class="fab fa-github"></i>
                                    </span>
                                    <span>Code</span>
                                </a> &nbsp;&nbsp;

                            </span>
                                                                                
                        </div>
                    </div>
                    
                </div>
            </div>
        </div>
    </section>


    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre>
                @article{auroracap,
                    title={AuroraCap: Efficient, Performant Video Detailed Captioning and a New Benchmark},
                    author={Wenhao Chai, Enxin Song, Yilun Du, Chenlin Meng, Vashisht Madhavan, Omer Bar-Tal, Jeng-Neng Hwang, Saining Xie, Christopher D. Manning},
                    year={2024},
                    journal={arXiv preprint arXiv:2410.03051},
                }
            </pre>
        </div>
    </section>


    <footer class="footer">
        <div align="center" class="container">
            <div class="columns is-centered">
                <div class="content is-small">
                    This website templated is borrowed from <a
                        href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
                </div>
            </div>
        </div>
    </footer>

</body>


</html>
